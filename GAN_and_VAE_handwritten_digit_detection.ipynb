{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZE3RqBMf8Ha",
        "outputId": "f5f048d6-c027-4000-ecec-6ce99ef2ad5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training GAN...\n",
            "GAN Epoch 1/5 completed\n",
            "GAN Epoch 2/5 completed\n",
            "GAN Epoch 3/5 completed\n",
            "GAN Epoch 4/5 completed\n",
            "GAN Epoch 5/5 completed\n",
            "\n",
            "Training Classifier...\n",
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 115ms/step - accuracy: 0.8834 - loss: 0.4019 - val_accuracy: 0.9832 - val_loss: 0.0535\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 113ms/step - accuracy: 0.9829 - loss: 0.0543 - val_accuracy: 0.9868 - val_loss: 0.0430\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 110ms/step - accuracy: 0.9891 - loss: 0.0349 - val_accuracy: 0.9874 - val_loss: 0.0371\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 112ms/step - accuracy: 0.9931 - loss: 0.0229 - val_accuracy: 0.9892 - val_loss: 0.0347\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 115ms/step - accuracy: 0.9947 - loss: 0.0171 - val_accuracy: 0.9890 - val_loss: 0.0328\n",
            "313/313 - 3s - 8ms/step - accuracy: 0.9890 - loss: 0.0328\n",
            "\n",
            "Test accuracy: 0.9890000224113464\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# Optimize dataset pipeline\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 128  # Reduced batch size for faster training\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\\\n",
        "    .shuffle(BUFFER_SIZE)\\\n",
        "    .batch(BATCH_SIZE)\\\n",
        "    .prefetch(tf.data.AUTOTUNE)  # Added prefetch for better performance\n",
        "\n",
        "def make_generator_model():\n",
        "    model = models.Sequential([\n",
        "        # Simplified generator architecture\n",
        "        layers.Dense(7*7*128, use_bias=False, input_shape=(100,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Reshape((7, 7, 128)),\n",
        "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = models.Sequential([\n",
        "        # Simplified discriminator architecture\n",
        "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Simplified classifier\n",
        "classifier = models.Sequential([\n",
        "    layers.Input(shape=(28, 28, 1)),  # Added input layer explicitly\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the classifier\n",
        "classifier.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "        disc_loss = cross_entropy(tf.ones_like(real_output), real_output) + \\\n",
        "                   cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "# Training loop\n",
        "EPOCHS = 5  # Reduced epochs\n",
        "\n",
        "# Train GAN\n",
        "print(\"Training GAN...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    for image_batch, _ in train_dataset:\n",
        "        train_step(image_batch)\n",
        "    print(f'GAN Epoch {epoch + 1}/{EPOCHS} completed')\n",
        "\n",
        "# Train classifier separately\n",
        "print(\"\\nTraining Classifier...\")\n",
        "classifier.fit(train_images, train_labels,\n",
        "              epochs=5,  # Reduced epochs\n",
        "              batch_size=128,\n",
        "              validation_data=(test_images, test_labels),\n",
        "              verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = classifier.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n",
        "\n",
        "# Visualize some predictions\n",
        "predictions = classifier.predict(test_images[:5])\n",
        "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
        "for i, ax in enumerate(axs):\n",
        "    ax.imshow(test_images[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f'Predicted: {np.argmax(predictions[i])}')\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TQNu9mCigUNl",
        "outputId": "c90a971a-f377-4588-b719-d841dc489305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training VAE...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 42ms/step - loss: 1.2888e-05 - val_loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - loss: 3.5295e-12 - val_loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 39ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "\n",
            "Training Classifier...\n",
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1100 - loss: 2.3020 - val_accuracy: 0.1135 - val_loss: 2.3011\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1124 - loss: 2.3014 - val_accuracy: 0.1135 - val_loss: 2.3012\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1130 - loss: 2.3010 - val_accuracy: 0.1135 - val_loss: 2.3011\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1137 - loss: 2.3011 - val_accuracy: 0.1135 - val_loss: 2.3011\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1114 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3012\n",
            "313/313 - 0s - 1ms/step - accuracy: 0.1135 - loss: 2.3012\n",
            "\n",
            "Test accuracy: 0.11349999904632568\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x600 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Reshape data\n",
        "x_train = x_train.reshape((len(x_train), 28, 28, 1))\n",
        "x_test = x_test.reshape((len(x_test), 28, 28, 1))\n",
        "\n",
        "# Network parameters\n",
        "latent_dim = 16\n",
        "\n",
        "# Custom sampling layer\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.random.normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Custom VAE model\n",
        "class VAE(models.Model):\n",
        "    def __init__(self, latent_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder_inputs = layers.Input(shape=(28, 28, 1))\n",
        "        self.x1 = layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')\n",
        "        self.x2 = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.dense1 = layers.Dense(32, activation='relu')\n",
        "\n",
        "        self.z_mean = layers.Dense(latent_dim)\n",
        "        self.z_log_var = layers.Dense(latent_dim)\n",
        "        self.sampling = Sampling()\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder_dense = layers.Dense(7 * 7 * 64, activation='relu')\n",
        "        self.decoder_reshape = layers.Reshape((7, 7, 64))\n",
        "        self.decoder_conv1 = layers.Conv2DTranspose(64, 3, activation='relu',\n",
        "                                                  strides=2, padding='same')\n",
        "        self.decoder_conv2 = layers.Conv2DTranspose(32, 3, activation='relu',\n",
        "                                                  strides=2, padding='same')\n",
        "        self.decoder_outputs = layers.Conv2DTranspose(1, 3, activation='sigmoid',\n",
        "                                                    padding='same')\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.x1(x)\n",
        "        x = self.x2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        z_mean = self.z_mean(x)\n",
        "        z_log_var = self.z_log_var(x)\n",
        "        z = self.sampling([z_mean, z_log_var])\n",
        "        return z_mean, z_log_var, z\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = self.decoder_dense(z)\n",
        "        x = self.decoder_reshape(x)\n",
        "        x = self.decoder_conv1(x)\n",
        "        x = self.decoder_conv2(x)\n",
        "        return self.decoder_outputs(x)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encode(inputs)\n",
        "        reconstructed = self.decode(z)\n",
        "        # Add KL divergence regularization loss\n",
        "        kl_loss = -0.5 * tf.reduce_mean(\n",
        "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "        )\n",
        "        self.add_loss(kl_loss)\n",
        "        return reconstructed\n",
        "\n",
        "# Create VAE model\n",
        "vae = VAE(latent_dim)\n",
        "\n",
        "# Compile VAE\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# Define and compile classifier\n",
        "classifier = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(latent_dim,)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "classifier.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train VAE\n",
        "print(\"Training VAE...\")\n",
        "vae.fit(x_train, x_train,\n",
        "        epochs=5,\n",
        "        batch_size=128,\n",
        "        validation_data=(x_test, x_test))\n",
        "\n",
        "# Function to get encodings\n",
        "def get_encodings(model, data):\n",
        "    return model.encode(data)[0]  # Get z_mean\n",
        "\n",
        "# Get latent space representations\n",
        "train_encoded = get_encodings(vae, x_train)\n",
        "test_encoded = get_encodings(vae, x_test)\n",
        "\n",
        "# Train classifier\n",
        "print(\"\\nTraining Classifier...\")\n",
        "classifier.fit(train_encoded, y_train,\n",
        "              epochs=5,\n",
        "              batch_size=128,\n",
        "              validation_data=(test_encoded, y_test))\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = classifier.evaluate(test_encoded, y_test, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n",
        "\n",
        "# Visualize predictions\n",
        "predictions = classifier.predict(test_encoded[:5])\n",
        "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
        "for i, ax in enumerate(axs):\n",
        "    ax.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f'Predicted: {np.argmax(predictions[i])}')\n",
        "    ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Visualize reconstructions\n",
        "n = 5\n",
        "original_images = x_test[:n]\n",
        "reconstructed_images = vae.predict(original_images)\n",
        "\n",
        "fig, axs = plt.subplots(2, n, figsize=(15, 6))\n",
        "for i in range(n):\n",
        "    # Original images\n",
        "    axs[0, i].imshow(original_images[i].reshape(28, 28), cmap='gray')\n",
        "    axs[0, i].axis('off')\n",
        "    axs[0, i].set_title('Original')\n",
        "\n",
        "    # Reconstructed images\n",
        "    axs[1, i].imshow(reconstructed_images[i].reshape(28, 28), cmap='gray')\n",
        "    axs[1, i].axis('off')\n",
        "    axs[1, i].set_title('Reconstructed')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIkLpa3dgcMG",
        "outputId": "6b1a2d04-b8a4-4ec7-f8ed-5c2634d3389f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MNIST dataset...\n",
            "Creating model...\n",
            "Starting training...\n",
            "Epoch 1/30, Batch 10, Loss: 0.9921\n",
            "Epoch 1/30, Batch 20, Loss: 0.7561\n",
            "Epoch 1/30, Batch 30, Loss: 0.6007\n",
            "Epoch 1/30, Batch 40, Loss: 0.5137\n",
            "Epoch 1/30, Batch 50, Loss: 0.4796\n",
            "Epoch 1/30, Batch 60, Loss: 0.3939\n",
            "Epoch 1/30, Batch 70, Loss: 0.3704\n",
            "Epoch 1/30, Batch 80, Loss: 0.3682\n",
            "Epoch 1/30, Batch 90, Loss: 0.3517\n",
            "Epoch 1/30, Batch 100, Loss: 0.3384\n",
            "Epoch 1/30, Batch 110, Loss: 0.3241\n",
            "Epoch 1/30, Batch 120, Loss: 0.3125\n",
            "Epoch 1/30, Batch 130, Loss: 0.3340\n",
            "Epoch 1/30, Batch 140, Loss: 0.3191\n",
            "Epoch 1/30, Batch 150, Loss: 0.2761\n",
            "Epoch 1/30, Batch 160, Loss: 0.2940\n",
            "Epoch 1/30, Batch 170, Loss: 0.2866\n",
            "Epoch 1/30, Batch 180, Loss: 0.2876\n",
            "Epoch 1/30, Batch 190, Loss: 0.2810\n",
            "Epoch 1/30, Batch 200, Loss: 0.2809\n",
            "Epoch 1/30, Batch 210, Loss: 0.2864\n",
            "Epoch 1/30, Batch 220, Loss: 0.2865\n",
            "Epoch 1/30, Batch 230, Loss: 0.2447\n",
            "Epoch 1/30, Average Loss: 0.4092\n",
            "Epoch 2/30, Batch 10, Loss: 0.2533\n",
            "Epoch 2/30, Batch 20, Loss: 0.2530\n",
            "Epoch 2/30, Batch 30, Loss: 0.2534\n",
            "Epoch 2/30, Batch 40, Loss: 0.2268\n",
            "Epoch 2/30, Batch 50, Loss: 0.2318\n",
            "Epoch 2/30, Batch 60, Loss: 0.2493\n",
            "Epoch 2/30, Batch 70, Loss: 0.2394\n",
            "Epoch 2/30, Batch 80, Loss: 0.2467\n",
            "Epoch 2/30, Batch 90, Loss: 0.2198\n",
            "Epoch 2/30, Batch 100, Loss: 0.2280\n",
            "Epoch 2/30, Batch 110, Loss: 0.2082\n",
            "Epoch 2/30, Batch 120, Loss: 0.2134\n",
            "Epoch 2/30, Batch 130, Loss: 0.2092\n",
            "Epoch 2/30, Batch 140, Loss: 0.2203\n",
            "Epoch 2/30, Batch 150, Loss: 0.2048\n",
            "Epoch 2/30, Batch 160, Loss: 0.2180\n",
            "Epoch 2/30, Batch 170, Loss: 0.2010\n",
            "Epoch 2/30, Batch 180, Loss: 0.2033\n",
            "Epoch 2/30, Batch 190, Loss: 0.2030\n",
            "Epoch 2/30, Batch 200, Loss: 0.2015\n",
            "Epoch 2/30, Batch 210, Loss: 0.1995\n",
            "Epoch 2/30, Batch 220, Loss: 0.2056\n",
            "Epoch 2/30, Batch 230, Loss: 0.1919\n",
            "Epoch 2/30, Average Loss: 0.2249\n",
            "Epoch 3/30, Batch 10, Loss: 0.2007\n",
            "Epoch 3/30, Batch 20, Loss: 0.2042\n",
            "Epoch 3/30, Batch 30, Loss: 0.1785\n",
            "Epoch 3/30, Batch 40, Loss: 0.1807\n",
            "Epoch 3/30, Batch 50, Loss: 0.1887\n",
            "Epoch 3/30, Batch 60, Loss: 0.1768\n",
            "Epoch 3/30, Batch 70, Loss: 0.1942\n",
            "Epoch 3/30, Batch 80, Loss: 0.1875\n",
            "Epoch 3/30, Batch 90, Loss: 0.1827\n",
            "Epoch 3/30, Batch 100, Loss: 0.1799\n",
            "Epoch 3/30, Batch 110, Loss: 0.1659\n",
            "Epoch 3/30, Batch 120, Loss: 0.1686\n",
            "Epoch 3/30, Batch 130, Loss: 0.1718\n",
            "Epoch 3/30, Batch 140, Loss: 0.1933\n",
            "Epoch 3/30, Batch 150, Loss: 0.1947\n",
            "Epoch 3/30, Batch 160, Loss: 0.1612\n",
            "Epoch 3/30, Batch 170, Loss: 0.1654\n",
            "Epoch 3/30, Batch 180, Loss: 0.1710\n",
            "Epoch 3/30, Batch 190, Loss: 0.1628\n",
            "Epoch 3/30, Batch 200, Loss: 0.1799\n",
            "Epoch 3/30, Batch 210, Loss: 0.1792\n",
            "Epoch 3/30, Batch 220, Loss: 0.1794\n",
            "Epoch 3/30, Batch 230, Loss: 0.1419\n",
            "Epoch 3/30, Average Loss: 0.1760\n",
            "Epoch 4/30, Batch 10, Loss: 0.1597\n",
            "Epoch 4/30, Batch 20, Loss: 0.1569\n",
            "Epoch 4/30, Batch 30, Loss: 0.1533\n",
            "Epoch 4/30, Batch 40, Loss: 0.1584\n",
            "Epoch 4/30, Batch 50, Loss: 0.1661\n",
            "Epoch 4/30, Batch 60, Loss: 0.1584\n",
            "Epoch 4/30, Batch 70, Loss: 0.1608\n",
            "Epoch 4/30, Batch 80, Loss: 0.1580\n",
            "Epoch 4/30, Batch 90, Loss: 0.1516\n",
            "Epoch 4/30, Batch 100, Loss: 0.1476\n",
            "Epoch 4/30, Batch 110, Loss: 0.1514\n",
            "Epoch 4/30, Batch 120, Loss: 0.1634\n",
            "Epoch 4/30, Batch 130, Loss: 0.1559\n",
            "Epoch 4/30, Batch 140, Loss: 0.1514\n",
            "Epoch 4/30, Batch 150, Loss: 0.1477\n",
            "Epoch 4/30, Batch 160, Loss: 0.1540\n",
            "Epoch 4/30, Batch 170, Loss: 0.1623\n",
            "Epoch 4/30, Batch 180, Loss: 0.1342\n",
            "Epoch 4/30, Batch 190, Loss: 0.1441\n",
            "Epoch 4/30, Batch 200, Loss: 0.1476\n",
            "Epoch 4/30, Batch 210, Loss: 0.1324\n",
            "Epoch 4/30, Batch 220, Loss: 0.1428\n",
            "Epoch 4/30, Batch 230, Loss: 0.1413\n",
            "Epoch 4/30, Average Loss: 0.1521\n",
            "Epoch 5/30, Batch 10, Loss: 0.1503\n",
            "Epoch 5/30, Batch 20, Loss: 0.1338\n",
            "Epoch 5/30, Batch 30, Loss: 0.1401\n",
            "Epoch 5/30, Batch 40, Loss: 0.1393\n",
            "Epoch 5/30, Batch 50, Loss: 0.1397\n",
            "Epoch 5/30, Batch 60, Loss: 0.1546\n",
            "Epoch 5/30, Batch 70, Loss: 0.1482\n",
            "Epoch 5/30, Batch 80, Loss: 0.1475\n",
            "Epoch 5/30, Batch 90, Loss: 0.1360\n",
            "Epoch 5/30, Batch 100, Loss: 0.1493\n",
            "Epoch 5/30, Batch 110, Loss: 0.1396\n",
            "Epoch 5/30, Batch 120, Loss: 0.1378\n",
            "Epoch 5/30, Batch 130, Loss: 0.1396\n",
            "Epoch 5/30, Batch 140, Loss: 0.1487\n",
            "Epoch 5/30, Batch 150, Loss: 0.1254\n",
            "Epoch 5/30, Batch 160, Loss: 0.1574\n",
            "Epoch 5/30, Batch 170, Loss: 0.1488\n",
            "Epoch 5/30, Batch 180, Loss: 0.1341\n",
            "Epoch 5/30, Batch 190, Loss: 0.1392\n",
            "Epoch 5/30, Batch 200, Loss: 0.1494\n",
            "Epoch 5/30, Batch 210, Loss: 0.1491\n",
            "Epoch 5/30, Batch 220, Loss: 0.1288\n",
            "Epoch 5/30, Batch 230, Loss: 0.1190\n",
            "Epoch 5/30, Average Loss: 0.1388\n",
            "Epoch 6/30, Batch 10, Loss: 0.1217\n",
            "Epoch 6/30, Batch 20, Loss: 0.1236\n",
            "Epoch 6/30, Batch 30, Loss: 0.1176\n",
            "Epoch 6/30, Batch 40, Loss: 0.1337\n",
            "Epoch 6/30, Batch 50, Loss: 0.1348\n",
            "Epoch 6/30, Batch 60, Loss: 0.1182\n",
            "Epoch 6/30, Batch 70, Loss: 0.1198\n",
            "Epoch 6/30, Batch 80, Loss: 0.1166\n",
            "Epoch 6/30, Batch 90, Loss: 0.1274\n",
            "Epoch 6/30, Batch 100, Loss: 0.1212\n",
            "Epoch 6/30, Batch 110, Loss: 0.1205\n",
            "Epoch 6/30, Batch 120, Loss: 0.1259\n",
            "Epoch 6/30, Batch 130, Loss: 0.1150\n",
            "Epoch 6/30, Batch 140, Loss: 0.1205\n",
            "Epoch 6/30, Batch 150, Loss: 0.1338\n",
            "Epoch 6/30, Batch 160, Loss: 0.1268\n",
            "Epoch 6/30, Batch 170, Loss: 0.1239\n",
            "Epoch 6/30, Batch 180, Loss: 0.1084\n",
            "Epoch 6/30, Batch 190, Loss: 0.1131\n",
            "Epoch 6/30, Batch 200, Loss: 0.1177\n",
            "Epoch 6/30, Batch 210, Loss: 0.1121\n",
            "Epoch 6/30, Batch 220, Loss: 0.1337\n",
            "Epoch 6/30, Batch 230, Loss: 0.1233\n",
            "Epoch 6/30, Average Loss: 0.1249\n",
            "Epoch 7/30, Batch 10, Loss: 0.1189\n",
            "Epoch 7/30, Batch 20, Loss: 0.1190\n",
            "Epoch 7/30, Batch 30, Loss: 0.1126\n",
            "Epoch 7/30, Batch 40, Loss: 0.1194\n",
            "Epoch 7/30, Batch 50, Loss: 0.1107\n",
            "Epoch 7/30, Batch 60, Loss: 0.1189\n",
            "Epoch 7/30, Batch 70, Loss: 0.1103\n",
            "Epoch 7/30, Batch 80, Loss: 0.1098\n",
            "Epoch 7/30, Batch 90, Loss: 0.1180\n",
            "Epoch 7/30, Batch 100, Loss: 0.1146\n",
            "Epoch 7/30, Batch 110, Loss: 0.1114\n",
            "Epoch 7/30, Batch 120, Loss: 0.1104\n",
            "Epoch 7/30, Batch 130, Loss: 0.1205\n",
            "Epoch 7/30, Batch 140, Loss: 0.1118\n",
            "Epoch 7/30, Batch 150, Loss: 0.1085\n",
            "Epoch 7/30, Batch 160, Loss: 0.1183\n",
            "Epoch 7/30, Batch 170, Loss: 0.1145\n",
            "Epoch 7/30, Batch 180, Loss: 0.1119\n",
            "Epoch 7/30, Batch 190, Loss: 0.1154\n",
            "Epoch 7/30, Batch 200, Loss: 0.1112\n",
            "Epoch 7/30, Batch 210, Loss: 0.1065\n",
            "Epoch 7/30, Batch 220, Loss: 0.1141\n",
            "Epoch 7/30, Batch 230, Loss: 0.1066\n",
            "Epoch 7/30, Average Loss: 0.1164\n",
            "Epoch 8/30, Batch 10, Loss: 0.1114\n",
            "Epoch 8/30, Batch 20, Loss: 0.1058\n",
            "Epoch 8/30, Batch 30, Loss: 0.1116\n",
            "Epoch 8/30, Batch 40, Loss: 0.1138\n",
            "Epoch 8/30, Batch 50, Loss: 0.1015\n",
            "Epoch 8/30, Batch 60, Loss: 0.1137\n",
            "Epoch 8/30, Batch 70, Loss: 0.1171\n",
            "Epoch 8/30, Batch 80, Loss: 0.1128\n",
            "Epoch 8/30, Batch 90, Loss: 0.1238\n",
            "Epoch 8/30, Batch 100, Loss: 0.1129\n",
            "Epoch 8/30, Batch 110, Loss: 0.1216\n",
            "Epoch 8/30, Batch 120, Loss: 0.1089\n",
            "Epoch 8/30, Batch 130, Loss: 0.1061\n",
            "Epoch 8/30, Batch 140, Loss: 0.1237\n",
            "Epoch 8/30, Batch 150, Loss: 0.1061\n",
            "Epoch 8/30, Batch 160, Loss: 0.1085\n",
            "Epoch 8/30, Batch 170, Loss: 0.1085\n",
            "Epoch 8/30, Batch 180, Loss: 0.0955\n",
            "Epoch 8/30, Batch 190, Loss: 0.1096\n",
            "Epoch 8/30, Batch 200, Loss: 0.1084\n",
            "Epoch 8/30, Batch 210, Loss: 0.1133\n",
            "Epoch 8/30, Batch 220, Loss: 0.1114\n",
            "Epoch 8/30, Batch 230, Loss: 0.1044\n",
            "Epoch 8/30, Average Loss: 0.1104\n",
            "Epoch 9/30, Batch 10, Loss: 0.1144\n",
            "Epoch 9/30, Batch 20, Loss: 0.1041\n",
            "Epoch 9/30, Batch 30, Loss: 0.1090\n",
            "Epoch 9/30, Batch 40, Loss: 0.1013\n",
            "Epoch 9/30, Batch 50, Loss: 0.0940\n",
            "Epoch 9/30, Batch 60, Loss: 0.1032\n",
            "Epoch 9/30, Batch 70, Loss: 0.1108\n",
            "Epoch 9/30, Batch 80, Loss: 0.1096\n",
            "Epoch 9/30, Batch 90, Loss: 0.0985\n",
            "Epoch 9/30, Batch 100, Loss: 0.1075\n",
            "Epoch 9/30, Batch 110, Loss: 0.0983\n",
            "Epoch 9/30, Batch 120, Loss: 0.1115\n",
            "Epoch 9/30, Batch 130, Loss: 0.0979\n",
            "Epoch 9/30, Batch 140, Loss: 0.1071\n",
            "Epoch 9/30, Batch 150, Loss: 0.1125\n",
            "Epoch 9/30, Batch 160, Loss: 0.1027\n",
            "Epoch 9/30, Batch 170, Loss: 0.1041\n",
            "Epoch 9/30, Batch 180, Loss: 0.0997\n",
            "Epoch 9/30, Batch 190, Loss: 0.1039\n",
            "Epoch 9/30, Batch 200, Loss: 0.1079\n",
            "Epoch 9/30, Batch 210, Loss: 0.1021\n",
            "Epoch 9/30, Batch 220, Loss: 0.0948\n",
            "Epoch 9/30, Batch 230, Loss: 0.1075\n",
            "Epoch 9/30, Average Loss: 0.1050\n",
            "Epoch 10/30, Batch 10, Loss: 0.0996\n",
            "Epoch 10/30, Batch 20, Loss: 0.1010\n",
            "Epoch 10/30, Batch 30, Loss: 0.1048\n",
            "Epoch 10/30, Batch 40, Loss: 0.1189\n",
            "Epoch 10/30, Batch 50, Loss: 0.1046\n",
            "Epoch 10/30, Batch 60, Loss: 0.1097\n",
            "Epoch 10/30, Batch 70, Loss: 0.0975\n",
            "Epoch 10/30, Batch 80, Loss: 0.1055\n",
            "Epoch 10/30, Batch 90, Loss: 0.0928\n",
            "Epoch 10/30, Batch 100, Loss: 0.0999\n",
            "Epoch 10/30, Batch 110, Loss: 0.1074\n",
            "Epoch 10/30, Batch 120, Loss: 0.1025\n",
            "Epoch 10/30, Batch 130, Loss: 0.1001\n",
            "Epoch 10/30, Batch 140, Loss: 0.1043\n",
            "Epoch 10/30, Batch 150, Loss: 0.1057\n",
            "Epoch 10/30, Batch 160, Loss: 0.1052\n",
            "Epoch 10/30, Batch 170, Loss: 0.0912\n",
            "Epoch 10/30, Batch 180, Loss: 0.1004\n",
            "Epoch 10/30, Batch 190, Loss: 0.1004\n",
            "Epoch 10/30, Batch 200, Loss: 0.0980\n",
            "Epoch 10/30, Batch 210, Loss: 0.0939\n",
            "Epoch 10/30, Batch 220, Loss: 0.0917\n",
            "Epoch 10/30, Batch 230, Loss: 0.1066\n",
            "Epoch 10/30, Average Loss: 0.1015\n",
            "Epoch 11/30, Batch 10, Loss: 0.0988\n",
            "Epoch 11/30, Batch 20, Loss: 0.0987\n",
            "Epoch 11/30, Batch 30, Loss: 0.1006\n",
            "Epoch 11/30, Batch 40, Loss: 0.0986\n",
            "Epoch 11/30, Batch 50, Loss: 0.0965\n",
            "Epoch 11/30, Batch 60, Loss: 0.1051\n",
            "Epoch 11/30, Batch 70, Loss: 0.1080\n",
            "Epoch 11/30, Batch 80, Loss: 0.0941\n",
            "Epoch 11/30, Batch 90, Loss: 0.0932\n",
            "Epoch 11/30, Batch 100, Loss: 0.0870\n",
            "Epoch 11/30, Batch 110, Loss: 0.0952\n",
            "Epoch 11/30, Batch 120, Loss: 0.0985\n",
            "Epoch 11/30, Batch 130, Loss: 0.1055\n",
            "Epoch 11/30, Batch 140, Loss: 0.0931\n",
            "Epoch 11/30, Batch 150, Loss: 0.1029\n",
            "Epoch 11/30, Batch 160, Loss: 0.1003\n",
            "Epoch 11/30, Batch 170, Loss: 0.0950\n",
            "Epoch 11/30, Batch 180, Loss: 0.1086\n",
            "Epoch 11/30, Batch 190, Loss: 0.0959\n",
            "Epoch 11/30, Batch 200, Loss: 0.1002\n",
            "Epoch 11/30, Batch 210, Loss: 0.0925\n",
            "Epoch 11/30, Batch 220, Loss: 0.0994\n",
            "Epoch 11/30, Batch 230, Loss: 0.1038\n",
            "Epoch 11/30, Average Loss: 0.0979\n",
            "Epoch 12/30, Batch 10, Loss: 0.1012\n",
            "Epoch 12/30, Batch 20, Loss: 0.0919\n",
            "Epoch 12/30, Batch 30, Loss: 0.0889\n",
            "Epoch 12/30, Batch 40, Loss: 0.0999\n",
            "Epoch 12/30, Batch 50, Loss: 0.0983\n",
            "Epoch 12/30, Batch 60, Loss: 0.0974\n",
            "Epoch 12/30, Batch 70, Loss: 0.1027\n",
            "Epoch 12/30, Batch 80, Loss: 0.1001\n",
            "Epoch 12/30, Batch 90, Loss: 0.0917\n",
            "Epoch 12/30, Batch 100, Loss: 0.0930\n",
            "Epoch 12/30, Batch 110, Loss: 0.0944\n",
            "Epoch 12/30, Batch 120, Loss: 0.1000\n",
            "Epoch 12/30, Batch 130, Loss: 0.1026\n",
            "Epoch 12/30, Batch 140, Loss: 0.0873\n",
            "Epoch 12/30, Batch 150, Loss: 0.0919\n",
            "Epoch 12/30, Batch 160, Loss: 0.0910\n",
            "Epoch 12/30, Batch 170, Loss: 0.0999\n",
            "Epoch 12/30, Batch 180, Loss: 0.1013\n",
            "Epoch 12/30, Batch 190, Loss: 0.0932\n",
            "Epoch 12/30, Batch 200, Loss: 0.0925\n",
            "Epoch 12/30, Batch 210, Loss: 0.0936\n",
            "Epoch 12/30, Batch 220, Loss: 0.0970\n",
            "Epoch 12/30, Batch 230, Loss: 0.0995\n",
            "Epoch 12/30, Average Loss: 0.0961\n",
            "Epoch 13/30, Batch 10, Loss: 0.0966\n",
            "Epoch 13/30, Batch 20, Loss: 0.0920\n",
            "Epoch 13/30, Batch 30, Loss: 0.0991\n",
            "Epoch 13/30, Batch 40, Loss: 0.0949\n",
            "Epoch 13/30, Batch 50, Loss: 0.0904\n",
            "Epoch 13/30, Batch 60, Loss: 0.0978\n",
            "Epoch 13/30, Batch 70, Loss: 0.0941\n",
            "Epoch 13/30, Batch 80, Loss: 0.0925\n",
            "Epoch 13/30, Batch 90, Loss: 0.0971\n",
            "Epoch 13/30, Batch 100, Loss: 0.0938\n",
            "Epoch 13/30, Batch 110, Loss: 0.0948\n",
            "Epoch 13/30, Batch 120, Loss: 0.0861\n",
            "Epoch 13/30, Batch 130, Loss: 0.1002\n",
            "Epoch 13/30, Batch 140, Loss: 0.0979\n",
            "Epoch 13/30, Batch 150, Loss: 0.0905\n",
            "Epoch 13/30, Batch 160, Loss: 0.0912\n",
            "Epoch 13/30, Batch 170, Loss: 0.0956\n",
            "Epoch 13/30, Batch 180, Loss: 0.0923\n",
            "Epoch 13/30, Batch 190, Loss: 0.0897\n",
            "Epoch 13/30, Batch 200, Loss: 0.1069\n",
            "Epoch 13/30, Batch 210, Loss: 0.0880\n",
            "Epoch 13/30, Batch 220, Loss: 0.0899\n",
            "Epoch 13/30, Batch 230, Loss: 0.0987\n",
            "Epoch 13/30, Average Loss: 0.0940\n",
            "Epoch 14/30, Batch 10, Loss: 0.0954\n",
            "Epoch 14/30, Batch 20, Loss: 0.0922\n",
            "Epoch 14/30, Batch 30, Loss: 0.0903\n",
            "Epoch 14/30, Batch 40, Loss: 0.0877\n",
            "Epoch 14/30, Batch 50, Loss: 0.0980\n",
            "Epoch 14/30, Batch 60, Loss: 0.0917\n",
            "Epoch 14/30, Batch 70, Loss: 0.0955\n",
            "Epoch 14/30, Batch 80, Loss: 0.0877\n",
            "Epoch 14/30, Batch 90, Loss: 0.0943\n",
            "Epoch 14/30, Batch 100, Loss: 0.0907\n",
            "Epoch 14/30, Batch 110, Loss: 0.0957\n",
            "Epoch 14/30, Batch 120, Loss: 0.1003\n",
            "Epoch 14/30, Batch 130, Loss: 0.0910\n",
            "Epoch 14/30, Batch 140, Loss: 0.0897\n",
            "Epoch 14/30, Batch 150, Loss: 0.0864\n",
            "Epoch 14/30, Batch 160, Loss: 0.0954\n",
            "Epoch 14/30, Batch 170, Loss: 0.0866\n",
            "Epoch 14/30, Batch 180, Loss: 0.0887\n",
            "Epoch 14/30, Batch 190, Loss: 0.0962\n",
            "Epoch 14/30, Batch 200, Loss: 0.0973\n",
            "Epoch 14/30, Batch 210, Loss: 0.0990\n",
            "Epoch 14/30, Batch 220, Loss: 0.0878\n",
            "Epoch 14/30, Batch 230, Loss: 0.0904\n",
            "Epoch 14/30, Average Loss: 0.0921\n",
            "Epoch 15/30, Batch 10, Loss: 0.1014\n",
            "Epoch 15/30, Batch 20, Loss: 0.0842\n",
            "Epoch 15/30, Batch 30, Loss: 0.0877\n",
            "Epoch 15/30, Batch 40, Loss: 0.0945\n",
            "Epoch 15/30, Batch 50, Loss: 0.0890\n",
            "Epoch 15/30, Batch 60, Loss: 0.0862\n",
            "Epoch 15/30, Batch 70, Loss: 0.0897\n",
            "Epoch 15/30, Batch 80, Loss: 0.0868\n",
            "Epoch 15/30, Batch 90, Loss: 0.0882\n",
            "Epoch 15/30, Batch 100, Loss: 0.0919\n",
            "Epoch 15/30, Batch 110, Loss: 0.0839\n",
            "Epoch 15/30, Batch 120, Loss: 0.0908\n",
            "Epoch 15/30, Batch 130, Loss: 0.0904\n",
            "Epoch 15/30, Batch 140, Loss: 0.0874\n",
            "Epoch 15/30, Batch 150, Loss: 0.0965\n",
            "Epoch 15/30, Batch 160, Loss: 0.0852\n",
            "Epoch 15/30, Batch 170, Loss: 0.0782\n",
            "Epoch 15/30, Batch 180, Loss: 0.0923\n",
            "Epoch 15/30, Batch 190, Loss: 0.0958\n",
            "Epoch 15/30, Batch 200, Loss: 0.0868\n",
            "Epoch 15/30, Batch 210, Loss: 0.0947\n",
            "Epoch 15/30, Batch 220, Loss: 0.0827\n",
            "Epoch 15/30, Batch 230, Loss: 0.0927\n",
            "Epoch 15/30, Average Loss: 0.0908\n",
            "Epoch 16/30, Batch 10, Loss: 0.0938\n",
            "Epoch 16/30, Batch 20, Loss: 0.0853\n",
            "Epoch 16/30, Batch 30, Loss: 0.0895\n",
            "Epoch 16/30, Batch 40, Loss: 0.0925\n",
            "Epoch 16/30, Batch 50, Loss: 0.0936\n",
            "Epoch 16/30, Batch 60, Loss: 0.0869\n",
            "Epoch 16/30, Batch 70, Loss: 0.0856\n",
            "Epoch 16/30, Batch 80, Loss: 0.0925\n",
            "Epoch 16/30, Batch 90, Loss: 0.0889\n",
            "Epoch 16/30, Batch 100, Loss: 0.0937\n",
            "Epoch 16/30, Batch 110, Loss: 0.0965\n",
            "Epoch 16/30, Batch 120, Loss: 0.0940\n",
            "Epoch 16/30, Batch 130, Loss: 0.0855\n",
            "Epoch 16/30, Batch 140, Loss: 0.0897\n",
            "Epoch 16/30, Batch 150, Loss: 0.0940\n",
            "Epoch 16/30, Batch 160, Loss: 0.0930\n",
            "Epoch 16/30, Batch 170, Loss: 0.0893\n",
            "Epoch 16/30, Batch 180, Loss: 0.0930\n",
            "Epoch 16/30, Batch 190, Loss: 0.0909\n",
            "Epoch 16/30, Batch 200, Loss: 0.0879\n",
            "Epoch 16/30, Batch 210, Loss: 0.0885\n",
            "Epoch 16/30, Batch 220, Loss: 0.0805\n",
            "Epoch 16/30, Batch 230, Loss: 0.0842\n",
            "Epoch 16/30, Average Loss: 0.0898\n",
            "Epoch 17/30, Batch 10, Loss: 0.0919\n",
            "Epoch 17/30, Batch 20, Loss: 0.0876\n",
            "Epoch 17/30, Batch 30, Loss: 0.0917\n",
            "Epoch 17/30, Batch 40, Loss: 0.0929\n",
            "Epoch 17/30, Batch 50, Loss: 0.0892\n",
            "Epoch 17/30, Batch 60, Loss: 0.0813\n",
            "Epoch 17/30, Batch 70, Loss: 0.0860\n",
            "Epoch 17/30, Batch 80, Loss: 0.0899\n",
            "Epoch 17/30, Batch 90, Loss: 0.0985\n",
            "Epoch 17/30, Batch 100, Loss: 0.0882\n",
            "Epoch 17/30, Batch 110, Loss: 0.0977\n",
            "Epoch 17/30, Batch 120, Loss: 0.0888\n",
            "Epoch 17/30, Batch 130, Loss: 0.0873\n",
            "Epoch 17/30, Batch 140, Loss: 0.0904\n",
            "Epoch 17/30, Batch 150, Loss: 0.0871\n",
            "Epoch 17/30, Batch 160, Loss: 0.0914\n",
            "Epoch 17/30, Batch 170, Loss: 0.0922\n",
            "Epoch 17/30, Batch 180, Loss: 0.0938\n",
            "Epoch 17/30, Batch 190, Loss: 0.0853\n",
            "Epoch 17/30, Batch 200, Loss: 0.0885\n",
            "Epoch 17/30, Batch 210, Loss: 0.0855\n",
            "Epoch 17/30, Batch 220, Loss: 0.0940\n",
            "Epoch 17/30, Batch 230, Loss: 0.0836\n",
            "Epoch 17/30, Average Loss: 0.0892\n",
            "Epoch 18/30, Batch 10, Loss: 0.0865\n",
            "Epoch 18/30, Batch 20, Loss: 0.0860\n",
            "Epoch 18/30, Batch 30, Loss: 0.0942\n",
            "Epoch 18/30, Batch 40, Loss: 0.0851\n",
            "Epoch 18/30, Batch 50, Loss: 0.0923\n",
            "Epoch 18/30, Batch 60, Loss: 0.0872\n",
            "Epoch 18/30, Batch 70, Loss: 0.0856\n",
            "Epoch 18/30, Batch 80, Loss: 0.0865\n",
            "Epoch 18/30, Batch 90, Loss: 0.0869\n",
            "Epoch 18/30, Batch 100, Loss: 0.0967\n",
            "Epoch 18/30, Batch 110, Loss: 0.0926\n",
            "Epoch 18/30, Batch 120, Loss: 0.0840\n",
            "Epoch 18/30, Batch 130, Loss: 0.0845\n",
            "Epoch 18/30, Batch 140, Loss: 0.0880\n",
            "Epoch 18/30, Batch 150, Loss: 0.0998\n",
            "Epoch 18/30, Batch 160, Loss: 0.0827\n",
            "Epoch 18/30, Batch 170, Loss: 0.0906\n",
            "Epoch 18/30, Batch 180, Loss: 0.0830\n",
            "Epoch 18/30, Batch 190, Loss: 0.0898\n",
            "Epoch 18/30, Batch 200, Loss: 0.0935\n",
            "Epoch 18/30, Batch 210, Loss: 0.0884\n",
            "Epoch 18/30, Batch 220, Loss: 0.0868\n",
            "Epoch 18/30, Batch 230, Loss: 0.0817\n",
            "Epoch 18/30, Average Loss: 0.0876\n",
            "Epoch 19/30, Batch 10, Loss: 0.0826\n",
            "Epoch 19/30, Batch 20, Loss: 0.0908\n",
            "Epoch 19/30, Batch 30, Loss: 0.0850\n",
            "Epoch 19/30, Batch 40, Loss: 0.0906\n",
            "Epoch 19/30, Batch 50, Loss: 0.0839\n",
            "Epoch 19/30, Batch 60, Loss: 0.0937\n",
            "Epoch 19/30, Batch 70, Loss: 0.0827\n",
            "Epoch 19/30, Batch 80, Loss: 0.0833\n",
            "Epoch 19/30, Batch 90, Loss: 0.0803\n",
            "Epoch 19/30, Batch 100, Loss: 0.0870\n",
            "Epoch 19/30, Batch 110, Loss: 0.0893\n",
            "Epoch 19/30, Batch 120, Loss: 0.0865\n",
            "Epoch 19/30, Batch 130, Loss: 0.0813\n",
            "Epoch 19/30, Batch 140, Loss: 0.0878\n",
            "Epoch 19/30, Batch 150, Loss: 0.0863\n",
            "Epoch 19/30, Batch 160, Loss: 0.0925\n",
            "Epoch 19/30, Batch 170, Loss: 0.0885\n",
            "Epoch 19/30, Batch 180, Loss: 0.0878\n",
            "Epoch 19/30, Batch 190, Loss: 0.0863\n",
            "Epoch 19/30, Batch 200, Loss: 0.0856\n",
            "Epoch 19/30, Batch 210, Loss: 0.0813\n",
            "Epoch 19/30, Batch 220, Loss: 0.0826\n",
            "Epoch 19/30, Batch 230, Loss: 0.0902\n",
            "Epoch 19/30, Average Loss: 0.0863\n",
            "Epoch 20/30, Batch 10, Loss: 0.0866\n",
            "Epoch 20/30, Batch 20, Loss: 0.0827\n",
            "Epoch 20/30, Batch 30, Loss: 0.0845\n",
            "Epoch 20/30, Batch 40, Loss: 0.0839\n",
            "Epoch 20/30, Batch 50, Loss: 0.0845\n",
            "Epoch 20/30, Batch 60, Loss: 0.0948\n",
            "Epoch 20/30, Batch 70, Loss: 0.0898\n",
            "Epoch 20/30, Batch 80, Loss: 0.0834\n",
            "Epoch 20/30, Batch 90, Loss: 0.0840\n",
            "Epoch 20/30, Batch 100, Loss: 0.0889\n",
            "Epoch 20/30, Batch 110, Loss: 0.0831\n",
            "Epoch 20/30, Batch 120, Loss: 0.0809\n",
            "Epoch 20/30, Batch 130, Loss: 0.0786\n",
            "Epoch 20/30, Batch 140, Loss: 0.0805\n",
            "Epoch 20/30, Batch 150, Loss: 0.0824\n",
            "Epoch 20/30, Batch 160, Loss: 0.0877\n",
            "Epoch 20/30, Batch 170, Loss: 0.0851\n",
            "Epoch 20/30, Batch 180, Loss: 0.0807\n",
            "Epoch 20/30, Batch 190, Loss: 0.0807\n",
            "Epoch 20/30, Batch 200, Loss: 0.0839\n",
            "Epoch 20/30, Batch 210, Loss: 0.0840\n",
            "Epoch 20/30, Batch 220, Loss: 0.0878\n",
            "Epoch 20/30, Batch 230, Loss: 0.0853\n",
            "Epoch 20/30, Average Loss: 0.0861\n",
            "Epoch 21/30, Batch 10, Loss: 0.0873\n",
            "Epoch 21/30, Batch 20, Loss: 0.0862\n",
            "Epoch 21/30, Batch 30, Loss: 0.0825\n",
            "Epoch 21/30, Batch 40, Loss: 0.0821\n",
            "Epoch 21/30, Batch 50, Loss: 0.0814\n",
            "Epoch 21/30, Batch 60, Loss: 0.0910\n",
            "Epoch 21/30, Batch 70, Loss: 0.0817\n",
            "Epoch 21/30, Batch 80, Loss: 0.0868\n",
            "Epoch 21/30, Batch 90, Loss: 0.0886\n",
            "Epoch 21/30, Batch 100, Loss: 0.0813\n",
            "Epoch 21/30, Batch 110, Loss: 0.0851\n",
            "Epoch 21/30, Batch 120, Loss: 0.0830\n",
            "Epoch 21/30, Batch 130, Loss: 0.0818\n",
            "Epoch 21/30, Batch 140, Loss: 0.0821\n",
            "Epoch 21/30, Batch 150, Loss: 0.0865\n",
            "Epoch 21/30, Batch 160, Loss: 0.0837\n",
            "Epoch 21/30, Batch 170, Loss: 0.0889\n",
            "Epoch 21/30, Batch 180, Loss: 0.0827\n",
            "Epoch 21/30, Batch 190, Loss: 0.0825\n",
            "Epoch 21/30, Batch 200, Loss: 0.0889\n",
            "Epoch 21/30, Batch 210, Loss: 0.0815\n",
            "Epoch 21/30, Batch 220, Loss: 0.0883\n",
            "Epoch 21/30, Batch 230, Loss: 0.0875\n",
            "Epoch 21/30, Average Loss: 0.0855\n",
            "Epoch 22/30, Batch 10, Loss: 0.0842\n",
            "Epoch 22/30, Batch 20, Loss: 0.0836\n",
            "Epoch 22/30, Batch 30, Loss: 0.0810\n",
            "Epoch 22/30, Batch 40, Loss: 0.0810\n",
            "Epoch 22/30, Batch 50, Loss: 0.0858\n",
            "Epoch 22/30, Batch 60, Loss: 0.0938\n",
            "Epoch 22/30, Batch 70, Loss: 0.0824\n",
            "Epoch 22/30, Batch 80, Loss: 0.0898\n",
            "Epoch 22/30, Batch 90, Loss: 0.0889\n",
            "Epoch 22/30, Batch 100, Loss: 0.0858\n",
            "Epoch 22/30, Batch 110, Loss: 0.0888\n",
            "Epoch 22/30, Batch 120, Loss: 0.0930\n",
            "Epoch 22/30, Batch 130, Loss: 0.0864\n",
            "Epoch 22/30, Batch 140, Loss: 0.0796\n",
            "Epoch 22/30, Batch 150, Loss: 0.0876\n",
            "Epoch 22/30, Batch 160, Loss: 0.0765\n",
            "Epoch 22/30, Batch 170, Loss: 0.0880\n",
            "Epoch 22/30, Batch 180, Loss: 0.0816\n",
            "Epoch 22/30, Batch 190, Loss: 0.0812\n",
            "Epoch 22/30, Batch 200, Loss: 0.0808\n",
            "Epoch 22/30, Batch 210, Loss: 0.0840\n",
            "Epoch 22/30, Batch 220, Loss: 0.0822\n",
            "Epoch 22/30, Batch 230, Loss: 0.0767\n",
            "Epoch 22/30, Average Loss: 0.0844\n",
            "Epoch 23/30, Batch 10, Loss: 0.0789\n",
            "Epoch 23/30, Batch 20, Loss: 0.0881\n",
            "Epoch 23/30, Batch 30, Loss: 0.0852\n",
            "Epoch 23/30, Batch 40, Loss: 0.0808\n",
            "Epoch 23/30, Batch 50, Loss: 0.0902\n",
            "Epoch 23/30, Batch 60, Loss: 0.0900\n",
            "Epoch 23/30, Batch 70, Loss: 0.0841\n",
            "Epoch 23/30, Batch 80, Loss: 0.0913\n",
            "Epoch 23/30, Batch 90, Loss: 0.0758\n",
            "Epoch 23/30, Batch 100, Loss: 0.0834\n",
            "Epoch 23/30, Batch 110, Loss: 0.0875\n",
            "Epoch 23/30, Batch 120, Loss: 0.0853\n",
            "Epoch 23/30, Batch 130, Loss: 0.0927\n",
            "Epoch 23/30, Batch 140, Loss: 0.0923\n",
            "Epoch 23/30, Batch 150, Loss: 0.0839\n",
            "Epoch 23/30, Batch 160, Loss: 0.0829\n",
            "Epoch 23/30, Batch 170, Loss: 0.0931\n",
            "Epoch 23/30, Batch 180, Loss: 0.0894\n",
            "Epoch 23/30, Batch 190, Loss: 0.0827\n",
            "Epoch 23/30, Batch 200, Loss: 0.0817\n",
            "Epoch 23/30, Batch 210, Loss: 0.0799\n",
            "Epoch 23/30, Batch 220, Loss: 0.0854\n",
            "Epoch 23/30, Batch 230, Loss: 0.0867\n",
            "Epoch 23/30, Average Loss: 0.0840\n",
            "Epoch 24/30, Batch 10, Loss: 0.0845\n",
            "Epoch 24/30, Batch 20, Loss: 0.0833\n",
            "Epoch 24/30, Batch 30, Loss: 0.0862\n",
            "Epoch 24/30, Batch 40, Loss: 0.0776\n",
            "Epoch 24/30, Batch 50, Loss: 0.0811\n",
            "Epoch 24/30, Batch 60, Loss: 0.0874\n",
            "Epoch 24/30, Batch 70, Loss: 0.0770\n",
            "Epoch 24/30, Batch 80, Loss: 0.0774\n",
            "Epoch 24/30, Batch 90, Loss: 0.0898\n",
            "Epoch 24/30, Batch 100, Loss: 0.0860\n",
            "Epoch 24/30, Batch 110, Loss: 0.0781\n",
            "Epoch 24/30, Batch 120, Loss: 0.0821\n",
            "Epoch 24/30, Batch 130, Loss: 0.0921\n",
            "Epoch 24/30, Batch 140, Loss: 0.0782\n",
            "Epoch 24/30, Batch 150, Loss: 0.0813\n",
            "Epoch 24/30, Batch 160, Loss: 0.0814\n",
            "Epoch 24/30, Batch 170, Loss: 0.0876\n",
            "Epoch 24/30, Batch 180, Loss: 0.0818\n",
            "Epoch 24/30, Batch 190, Loss: 0.0835\n",
            "Epoch 24/30, Batch 200, Loss: 0.0847\n",
            "Epoch 24/30, Batch 210, Loss: 0.0849\n",
            "Epoch 24/30, Batch 220, Loss: 0.0787\n",
            "Epoch 24/30, Batch 230, Loss: 0.0795\n",
            "Epoch 24/30, Average Loss: 0.0834\n",
            "Epoch 25/30, Batch 10, Loss: 0.0810\n",
            "Epoch 25/30, Batch 20, Loss: 0.0861\n",
            "Epoch 25/30, Batch 30, Loss: 0.0837\n",
            "Epoch 25/30, Batch 40, Loss: 0.0895\n",
            "Epoch 25/30, Batch 50, Loss: 0.0797\n",
            "Epoch 25/30, Batch 60, Loss: 0.0857\n",
            "Epoch 25/30, Batch 70, Loss: 0.0870\n",
            "Epoch 25/30, Batch 80, Loss: 0.0798\n",
            "Epoch 25/30, Batch 90, Loss: 0.0823\n",
            "Epoch 25/30, Batch 100, Loss: 0.0842\n",
            "Epoch 25/30, Batch 110, Loss: 0.0835\n",
            "Epoch 25/30, Batch 120, Loss: 0.0791\n",
            "Epoch 25/30, Batch 130, Loss: 0.0806\n",
            "Epoch 25/30, Batch 140, Loss: 0.0847\n",
            "Epoch 25/30, Batch 150, Loss: 0.0811\n",
            "Epoch 25/30, Batch 160, Loss: 0.0778\n",
            "Epoch 25/30, Batch 170, Loss: 0.0904\n",
            "Epoch 25/30, Batch 180, Loss: 0.0838\n",
            "Epoch 25/30, Batch 190, Loss: 0.0798\n",
            "Epoch 25/30, Batch 200, Loss: 0.0784\n",
            "Epoch 25/30, Batch 210, Loss: 0.0845\n",
            "Epoch 25/30, Batch 220, Loss: 0.0789\n",
            "Epoch 25/30, Batch 230, Loss: 0.0898\n",
            "Epoch 25/30, Average Loss: 0.0829\n",
            "Epoch 26/30, Batch 10, Loss: 0.0832\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "print(\"Loading MNIST dataset...\")\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# Optimize dataset pipeline\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "TIME_EMBEDDING_DIM = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\\\n",
        "    .shuffle(BUFFER_SIZE)\\\n",
        "    .batch(BATCH_SIZE)\\\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Diffusion hyperparameters\n",
        "timesteps = 20\n",
        "beta_start = 0.0001\n",
        "beta_end = 0.02\n",
        "betas = tf.linspace(beta_start, beta_end, timesteps)\n",
        "alphas = 1.0 - betas\n",
        "alphas_cumprod = tf.math.cumprod(alphas)\n",
        "alphas_cumprod_prev = tf.pad(alphas_cumprod[:-1], [[1, 0]], constant_values=1.0)\n",
        "sqrt_recip_alphas = tf.sqrt(1.0 / alphas)\n",
        "sqrt_alphas_cumprod = tf.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = tf.sqrt(1.0 - alphas_cumprod)\n",
        "posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "\n",
        "class TimeEmbedding(layers.Layer):\n",
        "    def __init__(self, embedding_dim=TIME_EMBEDDING_DIM, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.half_dim = embedding_dim // 2\n",
        "\n",
        "    def call(self, timesteps):\n",
        "        emb = tf.math.log(10000.0) / (self.half_dim - 1)\n",
        "        emb = tf.exp(tf.range(self.half_dim, dtype=tf.float32) * -emb)\n",
        "        emb = tf.cast(timesteps, dtype=tf.float32)[:, None] * emb[None, :]\n",
        "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=1)\n",
        "        return emb\n",
        "\n",
        "class DiffusionModel(models.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_embed = TimeEmbedding(TIME_EMBEDDING_DIM)\n",
        "        self.time_proj = layers.Dense(32, activation='swish')\n",
        "        self.time_proj2 = layers.Dense(32, activation='swish')\n",
        "\n",
        "        # Downsampling\n",
        "        self.conv1 = layers.Conv2D(32, 3, padding='same')\n",
        "        self.norm1 = layers.GroupNormalization()\n",
        "        self.act1 = layers.Activation('swish')\n",
        "\n",
        "        self.conv2 = layers.Conv2D(64, 3, strides=2, padding='same')\n",
        "        self.norm2 = layers.GroupNormalization()\n",
        "        self.act2 = layers.Activation('swish')\n",
        "\n",
        "        self.conv3 = layers.Conv2D(64, 3, strides=2, padding='same')\n",
        "        self.norm3 = layers.GroupNormalization()\n",
        "        self.act3 = layers.Activation('swish')\n",
        "\n",
        "        # Middle\n",
        "        self.conv_mid = layers.Conv2D(64, 3, padding='same')\n",
        "        self.norm_mid = layers.GroupNormalization()\n",
        "        self.act_mid = layers.Activation('swish')\n",
        "\n",
        "        # Upsampling\n",
        "        self.up1 = layers.UpSampling2D(2)\n",
        "        self.conv4 = layers.Conv2D(64, 3, padding='same')\n",
        "        self.norm4 = layers.GroupNormalization()\n",
        "        self.act4 = layers.Activation('swish')\n",
        "\n",
        "        self.up2 = layers.UpSampling2D(2)\n",
        "        self.conv5 = layers.Conv2D(32, 3, padding='same')\n",
        "        self.norm5 = layers.GroupNormalization()\n",
        "        self.act5 = layers.Activation('swish')\n",
        "\n",
        "        # Output\n",
        "        self.conv_out = layers.Conv2D(1, 3, padding='same')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, t = inputs\n",
        "\n",
        "        # Time embedding\n",
        "        t = self.time_embed(t)\n",
        "        t = self.time_proj(t)\n",
        "        t = self.time_proj2(t)\n",
        "\n",
        "        # Initial conv\n",
        "        h = self.conv1(x)\n",
        "        h = self.norm1(h)\n",
        "        h = self.act1(h)\n",
        "\n",
        "        # Add time embedding\n",
        "        t_emb = tf.expand_dims(tf.expand_dims(t, 1), 1)\n",
        "        h = h + t_emb\n",
        "\n",
        "        # Downsample\n",
        "        skip1 = h\n",
        "        h = self.conv2(h)\n",
        "        h = self.norm2(h)\n",
        "        h = self.act2(h)\n",
        "\n",
        "        skip2 = h\n",
        "        h = self.conv3(h)\n",
        "        h = self.norm3(h)\n",
        "        h = self.act3(h)\n",
        "\n",
        "        # Middle\n",
        "        h = self.conv_mid(h)\n",
        "        h = self.norm_mid(h)\n",
        "        h = self.act_mid(h)\n",
        "\n",
        "        # Upsample\n",
        "        h = self.up1(h)\n",
        "        h = layers.concatenate([h, skip2], axis=-1)\n",
        "        h = self.conv4(h)\n",
        "        h = self.norm4(h)\n",
        "        h = self.act4(h)\n",
        "\n",
        "        h = self.up2(h)\n",
        "        h = layers.concatenate([h, skip1], axis=-1)\n",
        "        h = self.conv5(h)\n",
        "        h = self.norm5(h)\n",
        "        h = self.act5(h)\n",
        "\n",
        "        # Output\n",
        "        return self.conv_out(h)\n",
        "\n",
        "# Create model\n",
        "print(\"Creating model...\")\n",
        "model = DiffusionModel()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "@tf.function\n",
        "def diffusion_step(batch):\n",
        "    t = tf.random.uniform(\n",
        "        shape=(tf.shape(batch)[0],),\n",
        "        minval=0,\n",
        "        maxval=timesteps,\n",
        "        dtype=tf.int32\n",
        "    )\n",
        "\n",
        "    noise = tf.random.normal(tf.shape(batch))\n",
        "    sqrt_alpha_cumprod_t = tf.gather(sqrt_alphas_cumprod, t)\n",
        "    sqrt_one_minus_alpha_cumprod_t = tf.gather(sqrt_one_minus_alphas_cumprod, t)\n",
        "\n",
        "    sqrt_alpha_cumprod_t = sqrt_alpha_cumprod_t[:, None, None, None]\n",
        "    sqrt_one_minus_alpha_cumprod_t = sqrt_one_minus_alpha_cumprod_t[:, None, None, None]\n",
        "\n",
        "    noisy_images = sqrt_alpha_cumprod_t * batch + sqrt_one_minus_alpha_cumprod_t * noise\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predicted_noise = model([noisy_images, t], training=True)\n",
        "        loss = tf.reduce_mean(tf.square(noise - predicted_noise))\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Training loop\n",
        "print(\"Starting training...\")\n",
        "EPOCHS = 30\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in train_dataset:\n",
        "        loss = diffusion_step(batch)\n",
        "        total_loss += loss\n",
        "        num_batches += 1\n",
        "\n",
        "        if num_batches % 10 == 0:\n",
        "            print(f'Epoch {epoch + 1}/{EPOCHS}, Batch {num_batches}, Loss: {loss:.4f}')\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}, Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "def generate_images(num_images=1):\n",
        "    x = tf.random.normal((num_images, 28, 28, 1))\n",
        "\n",
        "    for t in tf.range(timesteps - 1, -1, -1):\n",
        "        t_batch = tf.fill([num_images], t)\n",
        "        predicted_noise = model([x, t_batch], training=False)\n",
        "\n",
        "        alpha_t = tf.gather(alphas, t)\n",
        "        alpha_t_cumprod = tf.gather(alphas_cumprod, t)\n",
        "        beta_t = tf.gather(betas, t)\n",
        "\n",
        "        if t > 0:\n",
        "            noise = tf.random.normal(tf.shape(x))\n",
        "        else:\n",
        "            noise = tf.zeros_like(x)\n",
        "\n",
        "        x = (1 / tf.sqrt(alpha_t)) * (x - ((beta_t) / tf.sqrt(1 - alpha_t_cumprod)) * predicted_noise) + \\\n",
        "            tf.sqrt(beta_t) * noise\n",
        "\n",
        "    return x\n",
        "\n",
        "# Generate samples\n",
        "print(\"\\nGenerating samples...\")\n",
        "samples = generate_images(5)\n",
        "\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(samples[i].numpy().reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A88sZXUTP9rA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}